{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En faisant le produit avec la matrice adaptative si jamais un pays se retrouve seul dans une classe, toute la colonne de cette classe se retrouve à zéro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from adjency_matrix import AdaptativeMatrix, DTW,AgeReduction\n",
    "from gt_a_model import GCNLayer, GCNMultiLayer, Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AM = AdaptativeMatrix()\n",
    "dtw = DTW()\n",
    "AR = AgeReduction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjency_matrix(X: torch.Tensor, coord_countries: torch.Tensor):\n",
    "    \"\"\"\n",
    "    X is 3D tensor of mortality rates\n",
    "    coord_countries is 2D matrix contains longitude and latitude of each country. 1st column represents long and 2nd represents lat\n",
    "    \"\"\"\n",
    "    n_countries  = X.shape[0]\n",
    "    clusters = AM.adaptative_matrix(X)\n",
    "    dtw_matrix = dtw.DTW_Matrix(X)\n",
    "    long_lat_matrix = np.empty((n_countries, n_countries))\n",
    "    for i in range(n_countries):\n",
    "        for j in range(n_countries):\n",
    "            long_lat_matrix[i,j] = torch.sqrt(torch.mean((coord_countries[i]-coord_countries[j])**2))\n",
    "    \n",
    "    # \n",
    "    adjency_mat = dtw_matrix * long_lat_matrix\n",
    "    #print(\"adj_brut_matrix \\n\",adjency_mat)\n",
    "    for i in range(n_countries):\n",
    "        for j in range(n_countries):\n",
    "            if clusters[i] != clusters[j]:\n",
    "                adjency_mat[i,j] = 0.005\n",
    "    \n",
    "    #print(\"long_lat \\n\",long_lat_matrix)\n",
    "    print(\"clusters \\n\",clusters)\n",
    "    return adjency_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_2D_3D_product( A, B):\n",
    "        a_size = A.shape\n",
    "        b_size = B.shape\n",
    "        C = torch.Tensor(b_size)\n",
    "        for i in range(a_size[0]):\n",
    "            for j in range(a_size[1]):\n",
    "                C[i] += (A[i,j] * B[j])\n",
    "    \n",
    "        return C.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Importation des données de mortalité\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import mortality data for the different countries\n",
    "import os\n",
    " \n",
    "directory = '/Users/gojelastat/Desktop/Thèse/Projet 2/Données/Données GT-A'\n",
    "data={}\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and filename.endswith('.txt'):\n",
    "        data[filename.split('.')[0]]=pd.read_csv(f,header=1,delimiter=\"\\s+\") ### filename.split('.')[0] split the name by . and recover the code of the country\n",
    "        ### in this line, we fill the dictionary \"data\" with the different data of country and their code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Mettre les données au format adéquat \n",
    "C'est-à-dire sous forme de tenseur de taille M x T x A où M est le nombre de pays, T est la dimension du temps et A est la dimension de l'âge. Rappelons que ceci est fait pour s'adapter au cadre d'implémentation du modèle GT-A et ici on travaille avec les données des **hommes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fonction permettant de transformer les données dans la bonne numérisation\n",
    "def __data_load(data):\n",
    "    columns=data.columns\n",
    "    data['Age']=np.where(data['Age']!='110+',data['Age'],111)\n",
    "    for col in columns:\n",
    "        data[col]=np.where(data[col]!='.',data[col],9999)\n",
    "        data[col]=pd.to_numeric(data[col])\n",
    "\n",
    "    data=data[data['Age']<100]\n",
    "    data=data[data['Year']>=1950]\n",
    "    data=data[data['Year']<=2010]\n",
    "\n",
    "    #df_min=np.min(data['Male'])\n",
    "    #df_max=np.max(data['Male'])\n",
    "\n",
    "    #data['Male']=(data['Male']-df_min)/(df_max-df_min)\n",
    "    data.index=np.arange(data.shape[0])  ### renommer les index de 0 jusqu'à la taille de data\n",
    "    return data#,df_min,df_max\n",
    "\n",
    "\n",
    "\n",
    "### Transform the based dataset to matrix of mortality rates of male people in this case. \n",
    "#The matrix has age on row and year on columns\n",
    "def __data_reshaping(data,Gender=\"Male\"):\n",
    "    data=__data_load(data)\n",
    "    mat=pd.DataFrame(index=np.unique(data['Age']),columns=np.unique(data['Year']))\n",
    "    n=0\n",
    "    for j in range(mat.shape[1]):\n",
    "        for i in range(mat.shape[0]):\n",
    "            mat.iloc[mat.index[i],mat.index[j]]=data.loc[n+i,Gender]\n",
    "        n=n+mat.shape[0]\n",
    "    years=np.arange(1950,(1950+mat.shape[1]))\n",
    "    ages=np.arange(0,(mat.shape[0]))\n",
    "\n",
    "    #for col in years:\n",
    "    #    mat[col]=pd.to_numeric(mat[col])\n",
    "    return np.array(mat.T, dtype=np.float32) # ici on essaie de convertir en un tableau floattant, la transposée c'est parce que le code\n",
    "    # était fait pour sortir une matrice de taille A x T.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2010 - 1950 + 1\n",
    "A = 99 - 0 + 1\n",
    "X = torch.FloatTensor(len(data.keys()), T, A)\n",
    "\n",
    "countries = data.keys()\n",
    "for i,country in enumerate(countries):\n",
    "    X[i]= torch.tensor(__data_reshaping(data[country]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 61, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coordonnées géographique des pays \n",
    "Ici on oriente le globe en un repère orthonormé avec l'axe des abscisses orienté vers l'Est et l'axe des ordonnées orienté vers le Nord. Ces coordonnées ont été pris sur wikipédia. Dans la base de données HMD, il y a la base de données par régions du UK et pour toute la population UK. On a choisi d'utiliser la base du UK total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>39.3000</td>\n",
       "      <td>-8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR_NP</th>\n",
       "      <td>54.0000</td>\n",
       "      <td>-2.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEL</th>\n",
       "      <td>50.5000</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>-27.0000</td>\n",
       "      <td>133.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESP</th>\n",
       "      <td>40.0000</td>\n",
       "      <td>-4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISL</th>\n",
       "      <td>65.0000</td>\n",
       "      <td>-18.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUT</th>\n",
       "      <td>47.2000</td>\n",
       "      <td>13.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NZL_NP</th>\n",
       "      <td>-41.0000</td>\n",
       "      <td>174.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUN</th>\n",
       "      <td>47.0000</td>\n",
       "      <td>20.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRACNP</th>\n",
       "      <td>47.0000</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLD</th>\n",
       "      <td>51.5500</td>\n",
       "      <td>5.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNK</th>\n",
       "      <td>56.0000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>38.0000</td>\n",
       "      <td>-97.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPN</th>\n",
       "      <td>36.0000</td>\n",
       "      <td>138.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE</th>\n",
       "      <td>62.0000</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIN</th>\n",
       "      <td>64.0000</td>\n",
       "      <td>26.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CZE</th>\n",
       "      <td>49.0000</td>\n",
       "      <td>15.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITA</th>\n",
       "      <td>42.5001</td>\n",
       "      <td>12.5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BGR</th>\n",
       "      <td>43.0000</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVK</th>\n",
       "      <td>48.4000</td>\n",
       "      <td>19.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRL</th>\n",
       "      <td>53.0000</td>\n",
       "      <td>-8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAN</th>\n",
       "      <td>60.0000</td>\n",
       "      <td>-95.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Latitude  Longitude\n",
       "PRT      39.3000    -8.0000\n",
       "GBR_NP   54.0000    -2.3000\n",
       "BEL      50.5000     4.0000\n",
       "AUS     -27.0000   133.0000\n",
       "ESP      40.0000    -4.0000\n",
       "ISL      65.0000   -18.0000\n",
       "AUT      47.2000    13.2000\n",
       "NZL_NP  -41.0000   174.0000\n",
       "HUN      47.0000    20.0000\n",
       "FRACNP   47.0000     2.0000\n",
       "NLD      51.5500     5.3400\n",
       "DNK      56.0000    10.0000\n",
       "USA      38.0000   -97.0000\n",
       "JPN      36.0000   138.0000\n",
       "SWE      62.0000    15.0000\n",
       "FIN      64.0000    26.0000\n",
       "CZE      49.0000    15.0000\n",
       "ITA      42.5001    12.5001\n",
       "BGR      43.0000    25.0000\n",
       "SVK      48.4000    19.3000\n",
       "IRL      53.0000    -8.0000\n",
       "CAN      60.0000   -95.0000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = ['AUT','AUS','GBR_NP','ISL','NZL_NP', 'HUN', 'DNK', 'USA', 'JPN',\n",
    "           'SWE', 'FIN', 'CZE', 'BGR', 'SVK', 'IRL', 'CAN', 'PRT', 'BEL', 'ESP',\n",
    "           'FRACNP', 'NLD', 'ITA']\n",
    "coord = np.array([[47.20, 13.20],[-27.00, 133.00], [54.00, -2.30], [65.00, -18.00],\n",
    "                 [-41.00, 174.00], [47.00, 20.00], [56.00, 10.00], [38.00, -97.00],\n",
    "                 [36.00, 138.00], [62.00, 15.00], [64.00, 26.00], [49.00, 15.00],\n",
    "                 [43.00, 25.00], [48.40, 19.30], [53.00, -8.00], [60.00, -95.00],\n",
    "                 [39.30, -8.00], [50.50, 4.00], [40.00, -4.00], [47.00, 2.00], \n",
    "                 [51.55, 5.34], [42.5001, 12.5001]])\n",
    "\n",
    "geo_coord = pd.DataFrame(coord, index=country, columns=['Latitude', 'Longitude'])\n",
    "geo_coord = geo_coord.loc[list(data.keys())]\n",
    "geo_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Calcul de la matrice $A_{lat-long}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,  11.1485,  11.6069, 110.1742,   2.8714,  19.4999,  15.9977,\n",
       "         140.6629,  20.5340,   8.9244,  12.8066,  17.3622,  62.9392, 103.2640,\n",
       "          22.8505,  29.7161,  17.6506,  14.6713,  23.4807,  20.3482,   9.6874,\n",
       "          63.2356],\n",
       "        [ 11.1485,   0.0000,   5.0961, 111.5058,   9.9722,  13.5553,  11.9685,\n",
       "         141.6098,  16.5271,   5.8090,   5.6733,   8.8116,  67.9120, 100.0202,\n",
       "          13.4776,  21.2237,  12.7336,  13.2531,  20.8121,  15.7785,   4.0921,\n",
       "          65.6860],\n",
       "        [ 11.6069,   5.0961,   0.0000, 106.4125,   9.3341,  18.6313,   6.9112,\n",
       "         136.5142,  11.5812,   2.8504,   1.2038,   5.7554,  71.9627,  95.3054,\n",
       "          11.2528,  18.2517,   7.8502,   8.2538,  15.7678,  10.9202,   8.6675,\n",
       "          70.3251],\n",
       "        [110.1742, 111.5058, 106.4125,   0.0000, 107.8378, 125.0300,  99.6436,\n",
       "          30.6349,  95.5118, 106.3884, 105.9886, 104.9238, 169.0044,  44.6878,\n",
       "         104.5108,  99.3227,  99.2472,  98.3628,  91.0055,  96.4698, 114.6320,\n",
       "         172.5587],\n",
       "        [  2.8714,   9.9722,   9.3341, 107.8378,   0.0000,  20.2608,  13.1848,\n",
       "         138.2841,  17.6777,   6.5192,  10.5033,  15.0333,  65.7761, 100.4490,\n",
       "          20.5548,  27.1662,  14.8661,  11.8005,  20.6155,  17.5136,   9.6177,\n",
       "          65.8825],\n",
       "        [ 19.4999,  13.5553,  18.6313, 125.0300,  20.2608,   0.0000,  25.3996,\n",
       "         155.0806,  29.7321,  19.0263,  19.0481,  20.7966,  59.0339, 112.1985,\n",
       "          23.4307,  31.1207,  25.9326,  26.8002,  34.1541,  28.8691,  11.0454,\n",
       "          54.5619],\n",
       "        [ 15.9977,  11.9685,   6.9112,  99.6436,  13.1848,  25.3996,   0.0000,\n",
       "         129.6840,   4.8104,   7.9209,   6.3522,   6.6212,  78.1942,  88.6016,\n",
       "          10.5423,  14.9345,   1.8000,   3.3600,   8.8566,   4.3960,  15.5416,\n",
       "          77.0425],\n",
       "        [140.6629, 141.6098, 136.5142,  30.6349, 138.2841, 155.0806, 129.6840,\n",
       "           0.0000, 125.4193, 136.6163, 136.0362, 134.7312, 199.6021,  60.1041,\n",
       "         133.9590, 128.3141, 129.1917, 128.5583, 120.9483, 126.3417, 144.8447,\n",
       "         203.1773],\n",
       "        [ 20.5340,  16.5271,  11.5812,  95.5118,  17.6777,  29.7321,   4.8104,\n",
       "         125.4193,   0.0000,  12.7279,  10.8540,   9.5131,  82.9759,  83.8004,\n",
       "          11.1803,  12.7475,   3.8079,   6.1846,   4.5277,   1.1068,  20.2485,\n",
       "          81.8352],\n",
       "        [  8.9244,   5.8090,   2.8504, 106.3884,   6.5192,  19.0263,   7.9209,\n",
       "         136.6163,  12.7279,   0.0000,   3.9911,   8.5147,  70.2922,  96.4806,\n",
       "          14.0357,  20.7966,   9.3005,   8.0778,  16.5076,  12.2729,   8.2462,\n",
       "          69.2026],\n",
       "        [ 12.8066,   5.6733,   1.2038, 105.9886,  10.5033,  19.0481,   6.3522,\n",
       "         136.0362,  10.8540,   3.9911,   0.0000,   4.5562,  72.9968,  94.4470,\n",
       "          10.0628,  17.0563,   7.0646,   8.1599,  15.1595,  10.1194,   9.4884,\n",
       "          71.2022],\n",
       "        [ 17.3622,   8.8116,   5.7554, 104.9238,  15.0333,  20.7966,   6.6212,\n",
       "         134.7312,   9.5131,   8.5147,   4.5562,   0.0000,  76.7235,  91.6079,\n",
       "           5.5227,  12.6491,   6.0828,   9.7082,  14.0357,   8.4926,  12.9035,\n",
       "          74.3001],\n",
       "        [ 62.9392,  67.9120,  71.9627, 169.0044,  65.7761,  59.0339,  78.1942,\n",
       "         199.6021,  82.9759,  70.2922,  72.9968,  76.7235,   0.0000, 166.1761,\n",
       "          80.9938,  88.8960,  79.5770,  77.4936,  86.3394,  82.5647,  63.8201,\n",
       "          15.6205],\n",
       "        [103.2640, 100.0202,  95.3054,  44.6878, 100.4490, 112.1985,  88.6016,\n",
       "          60.1041,  83.8004,  96.4806,  94.4470,  91.6079, 166.1761,   0.0000,\n",
       "          88.8960,  81.6333,  87.4586,  88.8608,  80.0562,  84.3903, 103.9351,\n",
       "         165.6276],\n",
       "        [ 22.8505,  13.4776,  11.2528, 104.5108,  20.5548,  23.4307,  10.5423,\n",
       "         133.9590,  11.1803,  14.0357,  10.0628,   5.5227,  80.9938,  88.8960,\n",
       "           0.0000,   7.9057,   9.1924,  13.9014,  15.1822,  10.0859,  17.4642,\n",
       "          77.7946],\n",
       "        [ 29.7161,  21.2237,  18.2517,  99.3227,  27.1662,  31.1207,  14.9345,\n",
       "         128.3141,  12.7475,  20.7966,  17.0563,  12.6491,  88.8960,  81.6333,\n",
       "           7.9057,   0.0000,  13.1529,  17.9512,  14.8661,  12.0052,  25.2686,\n",
       "          85.6067],\n",
       "        [ 17.6506,  12.7336,   7.8502,  99.2472,  14.8661,  25.9326,   1.8000,\n",
       "         129.1917,   3.8079,   9.3005,   7.0646,   6.0828,  79.5770,  87.4586,\n",
       "           9.1924,  13.1529,   0.0000,   4.9243,   8.2462,   3.0700,  16.5076,\n",
       "          78.1697],\n",
       "        [ 14.6713,  13.2531,   8.2538,  98.3628,  11.8005,  26.8002,   3.3600,\n",
       "         128.5583,   6.1846,   8.0778,   8.1599,   9.7082,  77.4936,  88.8608,\n",
       "          13.9014,  17.9512,   4.9243,   0.0000,   8.8458,   6.3658,  16.2865,\n",
       "          77.0147],\n",
       "        [ 23.4807,  20.8121,  15.7678,  91.0055,  20.6155,  34.1541,   8.8566,\n",
       "         120.9483,   4.5277,  16.5076,  15.1595,  14.0357,  86.3394,  80.0562,\n",
       "          15.1822,  14.8661,   8.2462,   8.8458,   0.0000,   5.5520,  24.3824,\n",
       "          85.7001],\n",
       "        [ 20.3482,  15.7785,  10.9202,  96.4698,  17.5136,  28.8691,   4.3960,\n",
       "         126.3417,   1.1068,  12.2729,  10.1194,   8.4926,  82.5647,  84.3903,\n",
       "          10.0859,  12.0052,   3.0700,   6.3658,   5.5520,   0.0000,  19.5761,\n",
       "          81.2375],\n",
       "        [  9.6874,   4.0921,   8.6675, 114.6320,   9.6177,  11.0454,  15.5416,\n",
       "         144.8447,  20.2485,   8.2462,   9.4884,  12.9035,  63.8201, 103.9351,\n",
       "          17.4642,  25.2686,  16.5076,  16.2865,  24.3824,  19.5761,   0.0000,\n",
       "          61.7171],\n",
       "        [ 63.2356,  65.6860,  70.3251, 172.5587,  65.8825,  54.5619,  77.0425,\n",
       "         203.1773,  81.8352,  69.2026,  71.2022,  74.3001,  15.6205, 165.6276,\n",
       "          77.7946,  85.6067,  78.1697,  77.0147,  85.7001,  81.2375,  61.7171,\n",
       "           0.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_countries = len(data.keys())\n",
    "A_lat_long = torch.FloatTensor(n_countries, n_countries)\n",
    "for i, country_1 in enumerate(data.keys()):\n",
    "    for j, country_2 in enumerate(data.keys()):\n",
    "        A_lat_long[i,j] = np.sqrt(np.mean((geo_coord.loc[country_1]-geo_coord.loc[country_2])**2))\n",
    "\n",
    "A_lat_long"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Créer un objet geolocator\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "# Fonction pour obtenir les coordonnées d'un pays\n",
    "def get_country_coordinates(country_name):\n",
    "    location = geolocator.geocode(country_name)\n",
    "    if location:\n",
    "        return (location.latitude, location.longitude)\n",
    "    else:\n",
    "        return \"Pays non trouvé\"\n",
    "\n",
    "# Exemple : Obtenir les coordonnées de la France\n",
    "country = \"France\"\n",
    "coordinates = get_country_coordinates(country)\n",
    "print(f\"Coordonnées de {country} : {coordinates}\")\n",
    "\n",
    "# Exemple : Obtenir les coordonnées du Brésil\n",
    "country = \"Pays-bas\"\n",
    "coordinates = get_country_coordinates(country)\n",
    "print(f\"Coordonnées de {country} : {coordinates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette partie permet de convertir le dataframe en numpy floattant\n",
    "geo_coord = torch.FloatTensor(np.array(geo_coord, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance explained by principal components:  [0.51355214]\n",
      "The variance explained by principal components:  [0.77983756]\n",
      "The variance explained by principal components:  [0.38844029]\n",
      "The variance explained by principal components:  [0.54289204]\n",
      "The variance explained by principal components:  [0.6868258]\n",
      "The variance explained by principal components:  [0.99999979]\n",
      "The variance explained by principal components:  [0.41280576]\n",
      "The variance explained by principal components:  [0.31332616]\n",
      "The variance explained by principal components:  [0.62181391]\n",
      "The variance explained by principal components:  [0.76414144]\n",
      "The variance explained by principal components:  [0.59014299]\n",
      "The variance explained by principal components:  [0.39350316]\n",
      "The variance explained by principal components:  [0.76954034]\n",
      "The variance explained by principal components:  [0.7843422]\n",
      "The variance explained by principal components:  [0.44021979]\n",
      "The variance explained by principal components:  [0.51414641]\n",
      "The variance explained by principal components:  [0.39976796]\n",
      "The variance explained by principal components:  [0.76547806]\n",
      "The variance explained by principal components:  [0.69803336]\n",
      "The variance explained by principal components:  [0.56601672]\n",
      "The variance explained by principal components:  [0.45168781]\n",
      "The variance explained by principal components:  [0.48881103]\n",
      "The variance explained by principal components:  [0.51355214]\n",
      "The variance explained by principal components:  [0.77983756]\n",
      "The variance explained by principal components:  [0.38844029]\n",
      "The variance explained by principal components:  [0.54289204]\n",
      "The variance explained by principal components:  [0.6868258]\n",
      "The variance explained by principal components:  [0.99999979]\n",
      "The variance explained by principal components:  [0.41280576]\n",
      "The variance explained by principal components:  [0.31332616]\n",
      "The variance explained by principal components:  [0.62181391]\n",
      "The variance explained by principal components:  [0.76414144]\n",
      "The variance explained by principal components:  [0.59014299]\n",
      "The variance explained by principal components:  [0.39350316]\n",
      "The variance explained by principal components:  [0.76954034]\n",
      "The variance explained by principal components:  [0.7843422]\n",
      "The variance explained by principal components:  [0.44021979]\n",
      "The variance explained by principal components:  [0.51414641]\n",
      "The variance explained by principal components:  [0.39976796]\n",
      "The variance explained by principal components:  [0.76547806]\n",
      "The variance explained by principal components:  [0.69803336]\n",
      "The variance explained by principal components:  [0.56601672]\n",
      "The variance explained by principal components:  [0.45168781]\n",
      "The variance explained by principal components:  [0.48881103]\n",
      "clusters \n",
      " [2 2 2 2 2 1 2 0 2 2 2 0 0 2 2 0 2 2 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "A = adjency_matrix(X, geo_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Modélisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gt_a_model import GTA_Model\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m m1 \u001b[38;5;241m=\u001b[39m GCNLayer(in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m m1(X,A)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-deep/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-deep/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work_vs_code/multipopulation/GNN/gt_a_model.py:66\u001b[0m, in \u001b[0;36mGCNLayer.forward\u001b[0;34m(self, node_feats, adj_matrix)\u001b[0m\n\u001b[1;32m     63\u001b[0m adj_hat \u001b[38;5;241m=\u001b[39m adj_matrix \u001b[38;5;241m/\u001b[39m nodes_degrees\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# out = ÃH^(l)W^(l) + b\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(adj_hat, torch\u001b[38;5;241m.\u001b[39mmm(node_feats,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#if self.bias is not None:\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#    out = out + self.bias\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "m1 = GCNLayer(in_features=100, out_features=100)\n",
    "m1(X,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Tenseur 3D : par exemple, un batch de matrices 2D\n",
    "tensor_3d = torch.randn(5, 4, 6)  # (batch_size, m, n)\n",
    "\n",
    "# Tenseur 2D : par exemple, une matrice (n, p)\n",
    "tensor_2d = torch.randn(6, 3)  # (n, p)\n",
    "\n",
    "# Produit matriciel entre chaque \"matrice 2D\" du tenseur 3D et le tenseur 2D\n",
    "result = torch.matmul(tensor_3d, tensor_2d)\n",
    "\n",
    "print(result.shape)  # Résultat : (batch_size, m, p) -> (5, 4, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [1, 7] but got: [5, 7].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      2\u001b[0m A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m torch\u001b[38;5;241m.\u001b[39mbmm(A,X)\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [1, 7] but got: [5, 7]."
     ]
    }
   ],
   "source": [
    "X = torch.rand(5,7,5)\n",
    "A = torch.rand(1,7,7)\n",
    "torch.bmm(A,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model(X,A)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Boucle d'entraînement simple\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Zéro le gradient\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-deep/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-deep/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work_vs_code/multipopulation/GNN/gt_a_model.py:211\u001b[0m, in \u001b[0;36mGTA_Model.forward\u001b[0;34m(self, X, A)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, A):\n\u001b[0;32m--> 211\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn(X ,A)\n\u001b[1;32m    212\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(X)\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-deep/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-deep/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work_vs_code/multipopulation/GNN/gt_a_model.py:80\u001b[0m, in \u001b[0;36mGCNMultiLayer.forward\u001b[0;34m(self, nodes_features, adj_matrix)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes_features, adj_matrix):\n\u001b[0;32m---> 80\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn1(nodes_features, adj_matrix)\n\u001b[1;32m     81\u001b[0m     H \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(H)\n\u001b[1;32m     82\u001b[0m     H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn2(H, adj_matrix)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-deep/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-deep/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work_vs_code/multipopulation/GNN/gt_a_model.py:66\u001b[0m, in \u001b[0;36mGCNLayer.forward\u001b[0;34m(self, node_feats, adj_matrix)\u001b[0m\n\u001b[1;32m     63\u001b[0m adj_hat \u001b[38;5;241m=\u001b[39m adj_matrix \u001b[38;5;241m/\u001b[39m nodes_degrees\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# out = ÃH^(l)W^(l) + b\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(adj_hat, torch\u001b[38;5;241m.\u001b[39mmm(node_feats,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "\u001b[0;31mRuntimeError\u001b[0m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "model = GTA_Model()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model(X,A)\n",
    "\n",
    "# Boucle d'entraînement simple\n",
    "for epoch in range(200):\n",
    "    # Zéro le gradient\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(X, A)\n",
    "    \n",
    "    # Calcul de la perte\n",
    "    loss = criterion(output, Y)\n",
    "    \n",
    "    # Backward pass et optimisation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Affichage des informations\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
